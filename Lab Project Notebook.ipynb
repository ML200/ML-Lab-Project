{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dab942d",
   "metadata": {},
   "source": [
    "# Machine Learning Lab Project - Credit Card Overdue Likelihood Prediction\n",
    "##  Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7e57de",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "The data for this task is taken from [this](https://www.kaggle.com/datasets/rikdifos/credit-card-approval-prediction) kaggle dataset. The kaggle page provides two `.csv` files:\n",
    "- application_record.csv\n",
    "- credit_record.csv\n",
    "\n",
    "On a simple level, `application_record.csv` contains the customer data and `credit_record.csv` contains the customers credit history. The specific content is now investigated further.\n",
    "\n",
    "For beeing able to analyse the datasets, the necessary libraries are imported first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "511113b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1c65ba",
   "metadata": {},
   "source": [
    "In this next step the two `.csv` files are loaded into a pandas datafram. This enables an analysis with the full pandas funcionality, which makes the data understanding process way easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "2b7027e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df = pd.read_csv(\"Data/application_record.csv\")\n",
    "credit_df = pd.read_csv(\"Data/credit_record.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d875a2",
   "metadata": {},
   "source": [
    "### application_record.csv\n",
    "First, it is important to analyse the columns of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "0fd8bf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 438557 entries, 0 to 438556\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   ID                   438557 non-null  int64  \n",
      " 1   CODE_GENDER          438557 non-null  object \n",
      " 2   FLAG_OWN_CAR         438557 non-null  object \n",
      " 3   FLAG_OWN_REALTY      438557 non-null  object \n",
      " 4   CNT_CHILDREN         438557 non-null  int64  \n",
      " 5   AMT_INCOME_TOTAL     438557 non-null  float64\n",
      " 6   NAME_INCOME_TYPE     438557 non-null  object \n",
      " 7   NAME_EDUCATION_TYPE  438557 non-null  object \n",
      " 8   NAME_FAMILY_STATUS   438557 non-null  object \n",
      " 9   NAME_HOUSING_TYPE    438557 non-null  object \n",
      " 10  DAYS_BIRTH           438557 non-null  int64  \n",
      " 11  DAYS_EMPLOYED        438557 non-null  int64  \n",
      " 12  FLAG_MOBIL           438557 non-null  int64  \n",
      " 13  FLAG_WORK_PHONE      438557 non-null  int64  \n",
      " 14  FLAG_PHONE           438557 non-null  int64  \n",
      " 15  FLAG_EMAIL           438557 non-null  int64  \n",
      " 16  OCCUPATION_TYPE      304354 non-null  object \n",
      " 17  CNT_FAM_MEMBERS      438557 non-null  float64\n",
      "dtypes: float64(2), int64(8), object(8)\n",
      "memory usage: 60.2+ MB\n"
     ]
    }
   ],
   "source": [
    "customer_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4829b5e2",
   "metadata": {},
   "source": [
    "As can be seen above, the dataset consists of 17 columns, containing numeral as well as textual data. It also seems as if there is already an unique identifier for every customer in the column `ID`. A concrete description fo these different columns can be retrieved from the datasets [kaggle page](https://www.kaggle.com/datasets/rikdifos/credit-card-approval-prediction/data):\n",
    "\n",
    "|Feature name|Explanation|Remarks|\n",
    "|:-----------|:----------|:------|\n",
    "|ID \t     |Client number||\n",
    "|CODE_GENDER |\tGender \t||\n",
    "|FLAG_OWN_CAR| \tIs there a car \t||\n",
    "|FLAG_OWN_REALTY| \tIs there a property|| \t\n",
    "|CNT_CHILDREN| \tNumber of children \t||\n",
    "|AMT_INCOME_TOTAL| \tAnnual income \t||\n",
    "|NAME_INCOME_TYPE| \tIncome category \t||\n",
    "|NAME_EDUCATION_TYPE| \tEducation level ||\t\n",
    "|NAME_FAMILY_STATUS| \tMarital status \t||\n",
    "|NAME_HOUSING_TYPE| \tWay of living \t||\n",
    "|DAYS_BIRTH| \tBirthday |\tCount backwards from current day (0), -1 means yesterday|\n",
    "|DAYS_EMPLOYED| \tStart date of employment |\tCount backwards from current day(0). If positive, it means the person currently  unemployed.|\n",
    "|FLAG_MOBIL| \tIs there a mobile phone \t||\n",
    "|FLAG_WORK_PHONE| \tIs there a work phone \t||\n",
    "|FLAG_PHONE| \tIs there a phone \t||\n",
    "|FLAG_EMAIL| \tIs there an email \t||\n",
    "|OCCUPATION_TYPE| \tOccupation \t||\n",
    "|CNT_FAM_MEMBERS| \tFamily size||\n",
    "\n",
    "Now that the purpose of the columns is clear, the actual data can be analyzed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "104517cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>NAME_FAMILY_STATUS</th>\n",
       "      <th>NAME_HOUSING_TYPE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>FLAG_MOBIL</th>\n",
       "      <th>FLAG_WORK_PHONE</th>\n",
       "      <th>FLAG_PHONE</th>\n",
       "      <th>FLAG_EMAIL</th>\n",
       "      <th>OCCUPATION_TYPE</th>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5008804</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>-12005</td>\n",
       "      <td>-4542</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5008805</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>-12005</td>\n",
       "      <td>-4542</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5008806</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-21474</td>\n",
       "      <td>-1134</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Security staff</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5008808</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-19110</td>\n",
       "      <td>-3051</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5008809</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-19110</td>\n",
       "      <td>-3051</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
       "0  5008804           M            Y               Y             0   \n",
       "1  5008805           M            Y               Y             0   \n",
       "2  5008806           M            Y               Y             0   \n",
       "3  5008808           F            N               Y             0   \n",
       "4  5008809           F            N               Y             0   \n",
       "\n",
       "   AMT_INCOME_TOTAL      NAME_INCOME_TYPE            NAME_EDUCATION_TYPE  \\\n",
       "0          427500.0               Working               Higher education   \n",
       "1          427500.0               Working               Higher education   \n",
       "2          112500.0               Working  Secondary / secondary special   \n",
       "3          270000.0  Commercial associate  Secondary / secondary special   \n",
       "4          270000.0  Commercial associate  Secondary / secondary special   \n",
       "\n",
       "     NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
       "0        Civil marriage   Rented apartment      -12005          -4542   \n",
       "1        Civil marriage   Rented apartment      -12005          -4542   \n",
       "2               Married  House / apartment      -21474          -1134   \n",
       "3  Single / not married  House / apartment      -19110          -3051   \n",
       "4  Single / not married  House / apartment      -19110          -3051   \n",
       "\n",
       "   FLAG_MOBIL  FLAG_WORK_PHONE  FLAG_PHONE  FLAG_EMAIL OCCUPATION_TYPE  \\\n",
       "0           1                1           0           0             NaN   \n",
       "1           1                1           0           0             NaN   \n",
       "2           1                0           0           0  Security staff   \n",
       "3           1                0           1           1     Sales staff   \n",
       "4           1                0           1           1     Sales staff   \n",
       "\n",
       "   CNT_FAM_MEMBERS  \n",
       "0              2.0  \n",
       "1              2.0  \n",
       "2              2.0  \n",
       "3              1.0  \n",
       "4              1.0  "
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fef6505",
   "metadata": {},
   "source": [
    "From these first five entries several things can be observed:\n",
    "1. The ID does not start from 0 but seems to be unique.\n",
    "2. For the `CODE_GENDER` the flags `F` (Female) and `M` (Male) are used.\n",
    "3. For `FLAG_OWN_CAR` and `FLAG_OWN_REALTY` the flags `Y` (Yes) and `N` (No) are used.\n",
    "4. For `NAME_INCOME_TYPE`, `NAME_EDUCATION_TYPE`, `NAME_FAMILY_STATUS` and `NAME_HOUSING_TYPE` are textual fields, but seem to have only a few different values.\n",
    "5. `OCCUPATION_TYPE` is a textual field and the values seem to be very different (\"Freetext Field\").\n",
    "6. For `FLAG_MOBIL`, `FLAG_WORK_PHONE`, `FLAG_PHONE` and `FLAG_EMAIL` the flags 1 (Yes) and 0 (No) are used.\n",
    "\n",
    "Before basing the data perparation on these findings, the assumptions have to be validated:\n",
    "\n",
    "#### 1. Unique `ID`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "21461759",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID\n",
       "7137299    2\n",
       "7702238    2\n",
       "7282535    2\n",
       "7243768    2\n",
       "7050948    2\n",
       "          ..\n",
       "5690727    1\n",
       "6621262    1\n",
       "6621261    1\n",
       "6621260    1\n",
       "6842885    1\n",
       "Name: count, Length: 438510, dtype: int64"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_df['ID'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7df86a",
   "metadata": {},
   "source": [
    "The ouptut of the value count clearly shows that not every ID is unique. As some IDs are contained twice, the real amout of customers contained in the dataset is only 438510.\n",
    "#### 2. Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "97081a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CODE_GENDER\n",
       "F    294440\n",
       "M    144117\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_df['CODE_GENDER'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f68775",
   "metadata": {},
   "source": [
    "For the gender the assumption that only the flags `F` and `M` are used was correct.\n",
    "#### 3. Flag Car / Real-Estate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "ea31e73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLAG_OWN_CAR\n",
      "N    275459\n",
      "Y    163098\n",
      "Name: count, dtype: int64\n",
      "FLAG_OWN_REALTY\n",
      "Y    304074\n",
      "N    134483\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(customer_df['FLAG_OWN_CAR'].value_counts())\n",
    "print(customer_df['FLAG_OWN_REALTY'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9959af81",
   "metadata": {},
   "source": [
    "Also for the flags for the possesion of car and real-estate the assumption that there are only the flags `Y` and `N` was correct.\n",
    "#### 4. Text fields income, education, family and housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "2d09f567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME_INCOME_TYPE\n",
       "Working                 226104\n",
       "Commercial associate    100757\n",
       "Pensioner                75493\n",
       "State servant            36186\n",
       "Student                     17\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_df['NAME_INCOME_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a80281",
   "metadata": {},
   "source": [
    "As can be seen above, there are five different types of income. This means the column can be encoded without any problems and can be used for the modeling later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "b7e98f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME_EDUCATION_TYPE\n",
       "Secondary / secondary special    301821\n",
       "Higher education                 117522\n",
       "Incomplete higher                 14851\n",
       "Lower secondary                    4051\n",
       "Academic degree                     312\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_df['NAME_EDUCATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f773a454",
   "metadata": {},
   "source": [
    "The education field also consists of only five types and can therefore also be used for modelling without any problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "ac363c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME_FAMILY_STATUS\n",
       "Married                 299828\n",
       "Single / not married     55271\n",
       "Civil marriage           36532\n",
       "Separated                27251\n",
       "Widow                    19675\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_df['NAME_FAMILY_STATUS'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686e7be1",
   "metadata": {},
   "source": [
    "Also the family status has five different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "75506a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME_HOUSING_TYPE\n",
       "House / apartment      393831\n",
       "With parents            19077\n",
       "Municipal apartment     14214\n",
       "Rented apartment         5974\n",
       "Office apartment         3922\n",
       "Co-op apartment          1539\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_df['NAME_HOUSING_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2fc144",
   "metadata": {},
   "source": [
    "The housing has six different values, which is still acceptable.\n",
    "#### 5. Text field occupation type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "e8524c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCCUPATION_TYPE\n",
      "Laborers                 78240\n",
      "Core staff               43007\n",
      "Sales staff              41098\n",
      "Managers                 35487\n",
      "Drivers                  26090\n",
      "High skill tech staff    17289\n",
      "Accountants              15985\n",
      "Medicine staff           13520\n",
      "Cooking staff             8076\n",
      "Security staff            7993\n",
      "Cleaning staff            5845\n",
      "Private service staff     3456\n",
      "Low-skill Laborers        2140\n",
      "Secretaries               2044\n",
      "Waiters/barmen staff      1665\n",
      "Realty agents             1041\n",
      "HR staff                   774\n",
      "IT staff                   604\n",
      "Name: count, dtype: int64\n",
      "Amount of null values:  134203\n"
     ]
    }
   ],
   "source": [
    "print(customer_df['OCCUPATION_TYPE'].value_counts())\n",
    "print(\"Amount of null values: \", customer_df['OCCUPATION_TYPE'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c95a81d",
   "metadata": {},
   "source": [
    "Even though there are way less different values than expected (only 18), the column contains many null values, which may make it difficult to work with it.\n",
    "#### 6. Contact method flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "cc0977c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLAG_MOBIL\n",
      "1    438557\n",
      "Name: count, dtype: int64\n",
      "FLAG_WORK_PHONE\n",
      "0    348156\n",
      "1     90401\n",
      "Name: count, dtype: int64\n",
      "FLAG_PHONE\n",
      "0    312353\n",
      "1    126204\n",
      "Name: count, dtype: int64\n",
      "FLAG_EMAIL\n",
      "0    391102\n",
      "1     47455\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(customer_df['FLAG_MOBIL'].value_counts())\n",
    "print(customer_df['FLAG_WORK_PHONE'].value_counts())\n",
    "print(customer_df['FLAG_PHONE'].value_counts())\n",
    "print(customer_df['FLAG_EMAIL'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476de097",
   "metadata": {},
   "source": [
    "As expected, these columns only use the flags `1` and `0`. On top of that, column `FLAG_MOBIL` only contains the value `1`, which means all customers at least are registered with a mobile phone. Therefore, this column can be left out completely.\n",
    "### credit_record.csv\n",
    "Again, first analyze the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "476f8561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count    Dtype \n",
      "---  ------          --------------    ----- \n",
      " 0   ID              1048575 non-null  int64 \n",
      " 1   MONTHS_BALANCE  1048575 non-null  int64 \n",
      " 2   STATUS          1048575 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 24.0+ MB\n"
     ]
    }
   ],
   "source": [
    "credit_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11dd607",
   "metadata": {},
   "source": [
    "As can be seen above, this table only contains three columns. According to the [kaggle page](https://www.kaggle.com/datasets/rikdifos/credit-card-approval-prediction/data), these columns mean the following:\n",
    "\n",
    "|Feature name| \tExplanation |\tRemarks|\n",
    "|:-|:-|:-|\n",
    "|ID |\tClient number \t||\n",
    "|MONTHS_BALANCE |\tRecord month |\tThe month of the extracted data is the starting point, backwards, 0 is the current month, -1 is the previous month, and so on|\n",
    "|STATUS |\tStatus| \t0: 1-29 days past due 1: 30-59 days past due 2: 60-89 days overdue 3: 90-119 days overdue 4: 120-149 days overdue 5: Overdue or bad debts, write-offs for more than 150 days C: paid off that month X: No loan for the month|\n",
    "\n",
    "Checking for unique `ID` values now reveals for how many customers there exists credit data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "04598c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45985"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(credit_df['ID'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6412dea0",
   "metadata": {},
   "source": [
    "There is only credit data for 45985 customers, that means only parts of the `customer_df` can be used.\n",
    "As a last step check the values of the `STATUS` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "8d0e561b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATUS\n",
       "C    442031\n",
       "0    383120\n",
       "X    209230\n",
       "1     11090\n",
       "5      1693\n",
       "2       868\n",
       "3       320\n",
       "4       223\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_df['STATUS'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aef28f9",
   "metadata": {},
   "source": [
    "The information given on the kaggle page is correct, only the stated flags are used.\n",
    "### Summary\n",
    "Overall, the dataset consists of two parts: the customer data and the credit data. The customer data mostly contains information about income, job, family situation and contact methods as these are important aspects for evaluating the creditworthiness. The credit data is basically a credit history overview, showing for a given custumer and month if the credit was paid back on time. This credit data can now be used for calculating an \"overdue_likelyhood\" for every customer which states how likely it is for this specific customer to not pay it's credit back in time. This is an important information for a credit institute. Based on all the findings in this section the two datasets can now be prepared, connected and finally used for training a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61340257",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37e164e",
   "metadata": {},
   "source": [
    "Get the overdue likelyhood for the customers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "d62cc308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATUS       ID  overdue_likelihood\n",
      "0       5001711            1.000000\n",
      "1       5001712            0.526316\n",
      "2       5001713                 NaN\n",
      "3       5001714                 NaN\n",
      "4       5001715                 NaN\n",
      "The number of entries with NaN values in overdue_likelihood: 4536\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "grouped_df = credit_df.groupby('ID')['STATUS'].value_counts().unstack(fill_value=0)\n",
    "\n",
    "grouped_df['overdue_likelihood'] = 1 - (grouped_df['C'] / (grouped_df.sum(axis=1) - grouped_df['X']))\n",
    "\n",
    "result_df = grouped_df.reset_index()[['ID', 'overdue_likelihood']]\n",
    "\n",
    "print(result_df.head())\n",
    "\n",
    "nan_count = result_df['overdue_likelihood'].isna().sum()\n",
    "\n",
    "print(f'The number of entries with NaN values in overdue_likelihood: {nan_count}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ff13a5",
   "metadata": {},
   "source": [
    "That means ca. 33110 customers are really usable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2aa80c",
   "metadata": {},
   "source": [
    "Remove NaN entrys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "2461462c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of entries with NaN values in overdue_likelihood: 0\n"
     ]
    }
   ],
   "source": [
    "result_df.dropna(subset=['overdue_likelihood'], inplace=True)\n",
    "nan_count = result_df['overdue_likelihood'].isna().sum()\n",
    "\n",
    "print(f'The number of entries with NaN values in overdue_likelihood: {nan_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421c5c50",
   "metadata": {},
   "source": [
    "Merge the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "79178d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
      "0  5008804           M            Y               Y             0   \n",
      "1  5008805           M            Y               Y             0   \n",
      "2  5008806           M            Y               Y             0   \n",
      "3  5008808           F            N               Y             0   \n",
      "4  5008810           F            N               Y             0   \n",
      "\n",
      "   AMT_INCOME_TOTAL      NAME_INCOME_TYPE            NAME_EDUCATION_TYPE  \\\n",
      "0          427500.0               Working               Higher education   \n",
      "1          427500.0               Working               Higher education   \n",
      "2          112500.0               Working  Secondary / secondary special   \n",
      "3          270000.0  Commercial associate  Secondary / secondary special   \n",
      "4          270000.0  Commercial associate  Secondary / secondary special   \n",
      "\n",
      "     NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
      "0        Civil marriage   Rented apartment      -12005          -4542   \n",
      "1        Civil marriage   Rented apartment      -12005          -4542   \n",
      "2               Married  House / apartment      -21474          -1134   \n",
      "3  Single / not married  House / apartment      -19110          -3051   \n",
      "4  Single / not married  House / apartment      -19110          -3051   \n",
      "\n",
      "   FLAG_MOBIL  FLAG_WORK_PHONE  FLAG_PHONE  FLAG_EMAIL OCCUPATION_TYPE  \\\n",
      "0           1                1           0           0             NaN   \n",
      "1           1                1           0           0             NaN   \n",
      "2           1                0           0           0  Security staff   \n",
      "3           1                0           1           1     Sales staff   \n",
      "4           1                0           1           1     Sales staff   \n",
      "\n",
      "   CNT_FAM_MEMBERS  overdue_likelihood  \n",
      "0              2.0            0.133333  \n",
      "1              2.0            0.142857  \n",
      "2              2.0            0.500000  \n",
      "3              1.0            1.000000  \n",
      "4              1.0            0.285714  \n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(customer_df, result_df, on='ID', how='inner')\n",
    "print(merged_df.head())\n",
    "#print(len(merged_df['ID'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "c9c2bf99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overdue_class\n",
       "90-100%    15462\n",
       "10-20%      3423\n",
       "20-30%      2916\n",
       "0-10%       2715\n",
       "30-40%      2546\n",
       "40-50%      1984\n",
       "50-60%      1300\n",
       "60-70%      1111\n",
       "70-80%      1012\n",
       "80-90%       641\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "labels = ['0-10%', '10-20%', '20-30%', '30-40%', '40-50%', '50-60%', '60-70%', '70-80%', '80-90%', '90-100%']\n",
    "\n",
    "#bins = [0, 0.2, 0.4, 0.6,  0.8, 1]\n",
    "#labels = ['1', '2', '3', '4', '5']\n",
    "\n",
    "merged_df['overdue_class'] = pd.cut(merged_df['overdue_likelihood'], bins=bins, labels=labels, include_lowest=True)\n",
    "merged_df['overdue_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "606f7d26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CODE_GENDER  FLAG_OWN_CAR  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  \\\n",
      "0          1.0           1.0              1.0             0          427500.0   \n",
      "1          1.0           1.0              1.0             0          427500.0   \n",
      "2          1.0           1.0              1.0             0          112500.0   \n",
      "3          0.0           0.0              1.0             0          270000.0   \n",
      "4          0.0           0.0              1.0             0          270000.0   \n",
      "\n",
      "   NAME_EDUCATION_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  FLAG_MOBIL  \\\n",
      "0                  1.0      -12005          -4542           1   \n",
      "1                  1.0      -12005          -4542           1   \n",
      "2                  4.0      -21474          -1134           1   \n",
      "3                  4.0      -19110          -3051           1   \n",
      "4                  4.0      -19110          -3051           1   \n",
      "\n",
      "   FLAG_WORK_PHONE  ...  NAME_FAMILY_STATUS_Married  \\\n",
      "0                1  ...                       False   \n",
      "1                1  ...                       False   \n",
      "2                0  ...                        True   \n",
      "3                0  ...                       False   \n",
      "4                0  ...                       False   \n",
      "\n",
      "   NAME_FAMILY_STATUS_Separated  NAME_FAMILY_STATUS_Single / not married  \\\n",
      "0                         False                                    False   \n",
      "1                         False                                    False   \n",
      "2                         False                                    False   \n",
      "3                         False                                     True   \n",
      "4                         False                                     True   \n",
      "\n",
      "  NAME_FAMILY_STATUS_Widow  NAME_HOUSING_TYPE_Co-op apartment  \\\n",
      "0                    False                              False   \n",
      "1                    False                              False   \n",
      "2                    False                              False   \n",
      "3                    False                              False   \n",
      "4                    False                              False   \n",
      "\n",
      "   NAME_HOUSING_TYPE_House / apartment  NAME_HOUSING_TYPE_Municipal apartment  \\\n",
      "0                                False                                  False   \n",
      "1                                False                                  False   \n",
      "2                                 True                                  False   \n",
      "3                                 True                                  False   \n",
      "4                                 True                                  False   \n",
      "\n",
      "   NAME_HOUSING_TYPE_Office apartment  NAME_HOUSING_TYPE_Rented apartment  \\\n",
      "0                               False                                True   \n",
      "1                               False                                True   \n",
      "2                               False                               False   \n",
      "3                               False                               False   \n",
      "4                               False                               False   \n",
      "\n",
      "   NAME_HOUSING_TYPE_With parents  \n",
      "0                           False  \n",
      "1                           False  \n",
      "2                           False  \n",
      "3                           False  \n",
      "4                           False  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "one_hot_cols = ['NAME_INCOME_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE']\n",
    "ordinal_cols = ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'NAME_EDUCATION_TYPE']\n",
    "\n",
    "\n",
    "merged_df = merged_df.drop('OCCUPATION_TYPE', axis=1)\n",
    "merged_df = merged_df.drop('overdue_likelihood', axis=1)\n",
    "merged_df = merged_df.drop('ID', axis=1)\n",
    "\n",
    "df_ord = merged_df.copy()\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "df_ord[ordinal_cols] = ordinal_encoder.fit_transform(df_ord[ordinal_cols])\n",
    "\n",
    "df_enc = pd.get_dummies(df_ord, columns=one_hot_cols)\n",
    "\n",
    "print(df_enc.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "e8bbbeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CODE_GENDER  FLAG_OWN_CAR  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  \\\n",
      "0          1.0           1.0              1.0           0.0          0.258721   \n",
      "1          1.0           1.0              1.0           0.0          0.258721   \n",
      "2          1.0           1.0              1.0           0.0          0.055233   \n",
      "3          0.0           0.0              1.0           0.0          0.156977   \n",
      "4          0.0           0.0              1.0           0.0          0.156977   \n",
      "\n",
      "   NAME_EDUCATION_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  FLAG_MOBIL  \\\n",
      "0                 0.25    0.753539       0.029324         0.0   \n",
      "1                 0.25    0.753539       0.029324         0.0   \n",
      "2                 1.00    0.210810       0.038270         0.0   \n",
      "3                 1.00    0.346306       0.033237         0.0   \n",
      "4                 1.00    0.346306       0.033237         0.0   \n",
      "\n",
      "   FLAG_WORK_PHONE  ...  NAME_FAMILY_STATUS_Married  \\\n",
      "0              1.0  ...                         0.0   \n",
      "1              1.0  ...                         0.0   \n",
      "2              0.0  ...                         1.0   \n",
      "3              0.0  ...                         0.0   \n",
      "4              0.0  ...                         0.0   \n",
      "\n",
      "   NAME_FAMILY_STATUS_Separated  NAME_FAMILY_STATUS_Single / not married  \\\n",
      "0                           0.0                                      0.0   \n",
      "1                           0.0                                      0.0   \n",
      "2                           0.0                                      0.0   \n",
      "3                           0.0                                      1.0   \n",
      "4                           0.0                                      1.0   \n",
      "\n",
      "   NAME_FAMILY_STATUS_Widow  NAME_HOUSING_TYPE_Co-op apartment  \\\n",
      "0                       0.0                                0.0   \n",
      "1                       0.0                                0.0   \n",
      "2                       0.0                                0.0   \n",
      "3                       0.0                                0.0   \n",
      "4                       0.0                                0.0   \n",
      "\n",
      "   NAME_HOUSING_TYPE_House / apartment  NAME_HOUSING_TYPE_Municipal apartment  \\\n",
      "0                                  0.0                                    0.0   \n",
      "1                                  0.0                                    0.0   \n",
      "2                                  1.0                                    0.0   \n",
      "3                                  1.0                                    0.0   \n",
      "4                                  1.0                                    0.0   \n",
      "\n",
      "   NAME_HOUSING_TYPE_Office apartment  NAME_HOUSING_TYPE_Rented apartment  \\\n",
      "0                                 0.0                                 1.0   \n",
      "1                                 0.0                                 1.0   \n",
      "2                                 0.0                                 0.0   \n",
      "3                                 0.0                                 0.0   \n",
      "4                                 0.0                                 0.0   \n",
      "\n",
      "   NAME_HOUSING_TYPE_With parents  \n",
      "0                             0.0  \n",
      "1                             0.0  \n",
      "2                             0.0  \n",
      "3                             0.0  \n",
      "4                             0.0  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "X_enc = df_enc.drop('overdue_class', axis=1)\n",
    "Y = df_enc['overdue_class']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_enc)\n",
    "df_scaled = pd.DataFrame(X_scaled, columns= X_enc.columns)\n",
    "print(df_scaled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae813e4",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "- overdue-likelyhood zu labels\n",
    "- encoden\n",
    "    - Eig geht fast alles ordinal encoded\n",
    "    - OCCUPATION_TYPE fliegt ganz raus\n",
    "- scalen\n",
    "- random forest\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "51efbdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_scaled, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "b8de87fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 240 candidates, totalling 2400 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[277], line 23\u001b[0m\n\u001b[0;32m     18\u001b[0m forest \u001b[38;5;241m=\u001b[39m RandomForestClassifier(max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msqrt\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     19\u001b[0m                                 random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,                                \n\u001b[0;32m     20\u001b[0m                                 n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     22\u001b[0m forest_cv \u001b[38;5;241m=\u001b[39m GridSearchCV(forest, param_grid, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m#refit important.\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m forest_cv\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m (forest_cv\u001b[38;5;241m.\u001b[39mbest_estimator_)\n\u001b[0;32m     27\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m forest_cv\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "#rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=0, class_weight='balanced')\n",
    "\n",
    "#rf_classifier.fit(X_train, y_train)\n",
    "#y_test_pred = rf_classifier.predict(X_test)\n",
    "#accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "param_grid = {'n_estimators': np.array([25, 50, 100]), \n",
    "              'criterion':['gini','entropy'],\n",
    "              'min_samples_leaf':[3,5,10],\n",
    "              'max_depth': [1,2,3,4],\n",
    "              'class_weight':['balanced']}\n",
    "\n",
    "forest = RandomForestClassifier(max_features='sqrt',\n",
    "                                random_state=1,                                \n",
    "                                n_jobs=-1)\n",
    "\n",
    "forest_cv = GridSearchCV(forest, param_grid, scoring='accuracy', cv=10, verbose=3, n_jobs=-1, refit=True) #refit important.\n",
    "forest_cv.fit(X_train, y_train)\n",
    "\n",
    "print (forest_cv.best_estimator_)\n",
    "\n",
    "y_pred = forest_cv.best_estimator_.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)\n",
    "\n",
    "\n",
    "\n",
    "#print(accuracy)\n",
    "#print(y_test_pred)\n",
    "#print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84505270",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3357a52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
